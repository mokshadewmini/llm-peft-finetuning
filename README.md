# llm-peft-finetuning
# ðŸ§  PEFT (LoRA) Fine-Tuning of DistilBERT for Sentiment Classification

This project demonstrates how to fine-tune a DistilBERT model using the PEFT (LoRA) method for binary text classification.

## ðŸ”§ Tools & Libraries
- Hugging Face Transformers
- PEFT (LoRA)
- Datasets
- Weights & Biases (W&B)
- Gradio / FastAPI (deployment)

## ðŸš€ Whatâ€™s Included
- Fine-tuning code (Colab Notebook)
- Model uploaded to Hugging Face Hub
- W&B run tracking
- Inference + Deployment (Gradio or FastAPI)
- Hugging Face model
- W&B Dashboard

## ðŸ“¦ How to Run
Clone the repo and run the notebook or `app.py`.

Successfully tokenized and split the dataset!Â âœ…
![WhatsApp Image 2025-07-04 at 11 49 06_b774e5c0](https://github.com/user-attachments/assets/f3eafb02-ac79-4d09-9728-71bb0988829f)

fine-tuning with LoRA and integrated it with Weights & Biases (W&B) for experimentÂ tracking
![WhatsApp Image 2025-07-04 at 12 20 42_59edb144](https://github.com/user-attachments/assets/75bce8ed-3c3b-454d-b63f-a13ff6fade1d)

Gradio.live
![WhatsApp Image 2025-07-04 at 13 09 32_8ec8265d](https://github.com/user-attachments/assets/b8bd1f3d-4b0d-4680-b3d9-81e5199caba5)


![WhatsApp Image 2025-07-04 at 13 09 04_50f19ce5](https://github.com/user-attachments/assets/c10e2c4e-47ad-4e0c-ac5e-88baec6a11c4)

wandb.ai
![WhatsApp Image 2025-07-04 at 17 21 37_abb6748a](https://github.com/user-attachments/assets/4493e931-0860-4b16-885f-864a54c97de3)
![WhatsApp Image 2025-07-04 at 17 22 36_669d6520](https://github.com/user-attachments/assets/c95a128d-8146-4357-9e80-b4bf915ad53a)




